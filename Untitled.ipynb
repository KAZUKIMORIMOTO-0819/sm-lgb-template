{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424890cc-2a22-42d3-bee0-9fda9bf97642",
   "metadata": {},
   "source": [
    "# モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2211a5b4-2ebe-45b1-9125-3fec3a3f3e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterString,\n",
    "    ParameterInteger,\n",
    ")\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fee07f-588c-4352-8062-961ba7867174",
   "metadata": {},
   "source": [
    "# 各種設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30123fa5-4a4f-485e-9b07-89ced0f6fbeb",
   "metadata": {},
   "source": [
    "## セッションの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc70a30e-2b0e-4d5b-b3b4-a0fbf7044cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.session.Session object at 0x7eff5c367820>\n",
      "arn:aws:iam::706711397653:role/service-role/AmazonSageMaker-ExecutionRole-20240825T162290\n",
      "ap-northeast-1\n",
      "sagemaker-ap-northeast-1-706711397653\n"
     ]
    }
   ],
   "source": [
    "# セッションとロールの設定\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(sagemaker_session)\n",
    "print(role)\n",
    "print(region)\n",
    "print(default_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b8537-3baa-4ae2-8152-ec45c4d0237e",
   "metadata": {},
   "source": [
    "## パラメータの設定\n",
    "- パイプラインで使用するパラメータを定義。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c952bbd6-4fef-452e-9d68-9c7392232634",
   "metadata": {},
   "outputs": [],
   "source": [
    "### パラメータの定義\n",
    "processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"Approved\")\n",
    "\n",
    "### S3 key\n",
    "input_data_uri = f's3://{default_bucket}/lightgbm-pipeline/input/data.csv'\n",
    "output_data_uri = f's3://{default_bucket}/lightgbm-pipeline/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d1ca4-b768-4ad8-8a30-633bc1f78efb",
   "metadata": {},
   "source": [
    "# サンプルデータの作成\n",
    "- サンプルデータを作成し、S3にアップロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2d5979-3ed7-4f99-9a85-c3d2defc4a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-1-706711397653/lightgbm-pipeline/input/data.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20, n_informative=15, n_redundant=5, n_classes=2, random_state=42\n",
    ")\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "\n",
    "# データをS3にアップロード\n",
    "os.makedirs('data', exist_ok=True)\n",
    "df.to_csv('data/data.csv', index=False)\n",
    "sagemaker_session.upload_data(path='data/data.csv', \n",
    "                              bucket=default_bucket, \n",
    "                              key_prefix='lightgbm-pipeline/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a73aa7-7219-4e4e-9810-27b1d95ca75f",
   "metadata": {},
   "source": [
    "# パイプライン定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aece335-a129-42bc-9e7b-7cd91fa8ba92",
   "metadata": {},
   "source": [
    "## 前処理STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72843511-1d17-41ec-b2b6-11f61653b201",
   "metadata": {},
   "source": [
    "### スクリプト定義\n",
    "- データを訓練データと検証データに分割する前処理スクリプトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8568e557-82c8-46ff-8319-511ae3e7add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理スクリプトの作成\n",
    "processing_script = \"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"前処理を開始します。\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-bucket\", type=str)\n",
    "    parser.add_argument(\"--input-key\", type=str)\n",
    "    parser.add_argument(\"--output-train-bucket\", type=str)\n",
    "    parser.add_argument(\"--output-train-key\", type=str)\n",
    "    parser.add_argument(\"--output-validation-bucket\", type=str)\n",
    "    parser.add_argument(\"--output-validation-key\", type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    logger.info(\"S3からデータを読み込んでいます。\")\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=args.input_bucket, Key=args.input_key)\n",
    "    df = pd.read_csv(BytesIO(response['Body'].read()))\n",
    "\n",
    "    logger.info(f\"入力データの形状: {df.shape}\")\n",
    "\n",
    "    logger.info(\"データを訓練セットと検証セットに分割します。\")\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    logger.info(\"訓練データをS3に保存します。\")\n",
    "    csv_buffer = StringIO()\n",
    "    train_df.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(Bucket=args.output_train_bucket, Key=args.output_train_key, Body=csv_buffer.getvalue().encode('utf-8'))\n",
    "\n",
    "    logger.info(\"検証データをS3に保存します。\")\n",
    "    csv_buffer = StringIO()\n",
    "    val_df.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(Bucket=args.output_validation_bucket, Key=args.output_validation_key, Body=csv_buffer.getvalue().encode('utf-8'))\n",
    "\n",
    "    logger.info(\"前処理が完了しました。\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('preprocessing.py', 'w') as f:\n",
    "    f.write(processing_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954a17d-9f03-4a2c-a13d-0549b889ff48",
   "metadata": {},
   "source": [
    "### 前処理stepの定義\n",
    "- 前処理ステップをパイプラインに組み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef7baa3b-3919-4c6c-8167-a32fa2220cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "# 前処理ステップの定義\n",
    "script_processor = ScriptProcessor(\n",
    "    image_uri=sagemaker.image_uris.retrieve(framework='sklearn',\n",
    "                                            region=region,\n",
    "                                            version='0.23-1'),\n",
    "    command=['python3'],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name='lightgbm-preprocessing',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='Preprocessing',\n",
    "    processor=script_processor,\n",
    "    inputs=[],  # S3から直接読み込むため、inputsは不要\n",
    "    outputs=[],  # S3に直接保存するため、outputsは不要\n",
    "    code='preprocessing.py',\n",
    "    job_arguments=[\n",
    "        \"--input-bucket\", default_bucket,\n",
    "        \"--input-key\", \"lightgbm-pipeline/input/data.csv\",\n",
    "        \"--output-train-bucket\", default_bucket,\n",
    "        \"--output-train-key\", \"lightgbm-pipeline/output/train/train.csv\",\n",
    "        \"--output-validation-bucket\", default_bucket,\n",
    "        \"--output-validation-key\", \"lightgbm-pipeline/output/validation/validation.csv\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19043211-3150-4e52-9edc-a6ff90091001",
   "metadata": {},
   "source": [
    "## 訓練STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c358693-d05d-40e6-84f5-b625c3ff50df",
   "metadata": {},
   "source": [
    "### スクリプト定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d567461-fdf3-42b4-b7ab-590cb129b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習スクリプトの作成（S3から読み込み、S3に保存）\n",
    "training_script = \"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 必要なパッケージをインストール\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lightgbm\", \"optuna\", \"boto3\"])\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import boto3\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from io import BytesIO\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 10.0),\n",
    "    }\n",
    "\n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(params, train_dataset, valid_sets=[val_dataset], early_stopping_rounds=10, verbose_eval=False)\n",
    "    y_pred = model.predict(X_val)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    return auc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train-bucket\", type=str)\n",
    "    parser.add_argument(\"--train-key\", type=str)\n",
    "    parser.add_argument(\"--validation-bucket\", type=str)\n",
    "    parser.add_argument(\"--validation-key\", type=str)\n",
    "    parser.add_argument(\"--model-bucket\", type=str)\n",
    "    parser.add_argument(\"--model-key\", type=str)\n",
    "    parser.add_argument(\"--n-trials\", type=int, default=20)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    print(\"訓練データをS3から読み込んでいます。\")\n",
    "    response = s3.get_object(Bucket=args.train_bucket, Key=args.train_key)\n",
    "    train_df = pd.read_csv(BytesIO(response['Body'].read()))\n",
    "\n",
    "    print(\"検証データをS3から読み込んでいます。\")\n",
    "    response = s3.get_object(Bucket=args.validation_bucket, Key=args.validation_key)\n",
    "    val_df = pd.read_csv(BytesIO(response['Body'].read()))\n",
    "\n",
    "    y_train = train_df.pop('target')\n",
    "    X_train = train_df\n",
    "    y_val = val_df.pop('target')\n",
    "    X_val = val_df\n",
    "\n",
    "    # Optunaによるハイパーパラメータ最適化\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val), n_trials=args.n_trials)\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "    print('  AUC: {}'.format(trial.value))\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))\n",
    "\n",
    "    # 最適なハイパーパラメータでモデルを再学習\n",
    "    best_params = trial.params\n",
    "    best_params['objective'] = 'binary'\n",
    "    best_params['metric'] = 'auc'\n",
    "    best_params['verbosity'] = -1\n",
    "    best_params['boosting_type'] = 'gbdt'\n",
    "\n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(best_params, train_dataset, valid_sets=[val_dataset], early_stopping_rounds=10)\n",
    "\n",
    "    # モデルをS3に保存\n",
    "    import tempfile\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        model_path = os.path.join(tmpdir, \"model.txt\")\n",
    "        model.save_model(model_path)\n",
    "        with open(model_path, 'rb') as f:\n",
    "            s3.put_object(Bucket=args.model_bucket, Key=args.model_key, Body=f)\n",
    "\"\"\"\n",
    "\n",
    "with open('train.py', 'w') as f:\n",
    "    f.write(training_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd20d00-25d7-4b3e-bbfe-a945bbc44867",
   "metadata": {},
   "source": [
    "### 訓練stepの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b31775e-bdbe-4f44-b0cb-5997b2179b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "# Estimatorの定義\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    role=role,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    framework_version='0.23-1',\n",
    "    base_job_name='lightgbm-training',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\n",
    "        'n-trials': 50,\n",
    "        'train-bucket': default_bucket,\n",
    "        'train-key': 'lightgbm-pipeline/output/train/train.csv',\n",
    "        'validation-bucket': default_bucket,\n",
    "        'validation-key': 'lightgbm-pipeline/output/validation/validation.csv',\n",
    "        'model-bucket': default_bucket,\n",
    "        'model-key': 'lightgbm-pipeline/output/model/model.txt'\n",
    "    },\n",
    ")\n",
    "\n",
    "# TrainingStepの定義\n",
    "training_step = TrainingStep(\n",
    "    name='Training',\n",
    "    estimator=sklearn_estimator,\n",
    "    inputs={\n",
    "        'train': sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f's3://{default_bucket}/lightgbm-pipeline/output/train/train.csv',\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfea92-0961-4055-9dd0-59be5af137b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "354dd4fe-0768-4581-9c7b-6810bc6536ce",
   "metadata": {},
   "source": [
    "## パイプライン定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6544097-bcf2-404b-9b32-c412a75e8cb1",
   "metadata": {},
   "source": [
    "### パイプラインの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4787ebf3-45cf-4ddc-907c-a1eb74091cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name='LightGBM-Pipeline-Optuna',\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "    ],\n",
    "    steps=[processing_step,\n",
    "          training_step,\n",
    "          ],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d49649-afbf-4bc5-a4e6-766f38e96b62",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1eacc107-b807-4bbf-8814-85e18caa2cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "# パイプラインの作成と実行\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f64a5fc-7444-4c09-b822-640b3dcf6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'Preprocessing',\n",
       "  'StartTime': datetime.datetime(2024, 9, 21, 6, 56, 43, 408000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:ap-northeast-1:706711397653:processing-job/pipelines-heuntu5mx8dg-Preprocessing-7jFxMsrkZz'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'Training',\n",
       "  'StartTime': datetime.datetime(2024, 9, 21, 6, 56, 43, 408000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:ap-northeast-1:706711397653:training-job/pipelines-heuntu5mx8dg-Training-f05wpx93HZ'}},\n",
       "  'AttemptCount': 1}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b275d8b-7c62-4a46-b59f-00969d7690b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
